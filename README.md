
# ‚úàÔ∏è Plataforma de Ingenier√≠a de Datos: Vuelos A√©reo - ETL H√≠brido

![Descripci√≥n de la imagen](https://github.com/usertestdata/project_data/blob/main/extras/terraform/img/arquitectura.png?raw=true)


## üìú 1. Visi√≥n General del Proyecto

Este proyecto establece una **Plataforma de Ingenier√≠a de Datos H√≠brida** dise√±ada para analizar el rendimiento operativo y la rentabilidad de vuelos. La soluci√≥n utiliza una **Lakehouse Architecture** en Databricks, gestionada por **Terraform** e orquestada por **Azure Data Factory (ADF)**.

El sistema procesa dos flujos de datos esenciales:

1.  **Dataset 1 (Batch):** Datos hist√≥ricos de tarifas, capacidad y rentabilidad.
2.  **Dataset 2 (Streaming):** Eventos en tiempo casi real de seguimiento operativo y estado de vuelos (Event Hubs).

El objetivo es implementar y probar los diferentes servicios de azure enfocado a la ingenieria de datos.

La utilizacion de terraform ayuda a levantar algunos sevicios pero requiere configurcacion posterior que se mencionara en el apartado de "Ejecuci√≥n del Pipeline"

Todos los datos son random generados con un script de python. el codigo de terrafrom y script de agregara en una carpeta llamada "extras"
-----

## üíª 2. Tecnolog√≠as Clave

| Categor√≠a | Herramienta | Uso en el Proyecto |
| :--- | :--- | :--- |
| **Infraestructura (IaC)** | **Terraform** | Despliegue automatizado de todos los recursos en Azure: ADLS Gen2, Azure Data Factory (ADF), Azure Key Vault (AKV) y el *Workspace* de Databricks. |
| **Orquestaci√≥n** | **Azure Data Factory (ADF)** | Gesti√≥n del flujo de datos, ejecuci√≥n programada de *notebooks* de Databricks (Batch) y monitorizaci√≥n continua del *pipeline* de *streaming*. |
| **Procesamiento** | **Databricks (PySpark)** | Limpieza, transformaci√≥n ELT/ETL y agregaci√≥n de datos.  |
| **Streaming** | **Azure Event Hubs** | Ingesta de datos operativos de vuelos en tiempo casi real (Dataset 2). |
| **Almacenamiento** | **Delta Lake** | Implementaci√≥n de las capas Bronze, Silver y Gold. |
| **Visualizaci√≥n** | **Databricks SQL** | Creaci√≥n del *dashboard* final que consume la Capa Gold. |

-----

## üåä 3. Arquitectura del Lakehouse (Capas de Datos)

El flujo de datos sigue el est√°ndar Lakehouse (Medallion Architecture) en Delta Lake:

### 3.1. ü•â Capa BRONZE (Datos Crudos)

  * **Descripci√≥n:** Zona de aterrizaje que contiene la r√©plica exacta de las fuentes de datos.
  * **Contenido:** Archivos CSV hist√≥ricos (generado con script) y eventos binarios sin procesar de Event Hubs.

### 3.2. ü•à Capa SILVER (Limpieza y Enriquecimiento)

  * **Descripci√≥n:** Datos limpios, normalizados y listos para la agregaci√≥n.
  * **Transformaciones Clave:** Limpieza de nulos, conversi√≥n de tipos, normalizaci√≥n de `Estado_Actual`, c√°lculo de KPIs iniciales y parsing de JSON del *stream*.

### 3.3. ü•á Capa GOLD (M√©tricas de Negocio)

  * **Descripci√≥n:** Tablas agregadas y optimizadas para el consumo de BI.
  * **Tablas Resultantes:**
    1.  **`rendimiento_historico_vuelos`:** Agregaci√≥n del **Dataset 1** (Batch) por `Aerol√≠nea` y `Mes/A√±o`. M√©tricas: `SUM(ingreso_total)`, `AVG(load_factor)`.
    2.  **`estado_operacional_actual`:** Resultado del *pipeline* de **Streaming**. Ofrece el **√∫ltimo estado operativo** de cada vuelo activo, unido con sus datos hist√≥ricos de rentabilidad.

-----

## ‚öôÔ∏è 4. Pipelines de Procesamiento y L√≥gica Clave

El proyecto utiliza un **proceso h√≠brido** para gestionar la actualizaci√≥n continua y la agregaci√≥n hist√≥rica.

### 4.1. ‚û°Ô∏è Pipeline Batch (Dataset 1)

  * **Mecanismo:** Procesamiento y escritura de datos est√°ticos (`df.write.format("delta").saveAsTable(...)`).
  * **L√≥gica de Gold:** Agregaci√≥n final (`groupBy` y `agg`) de las m√©tricas de rentabilidad y capacidad para alimentar los *reports* de tendencia.

### 4.2. üöÄ Pipeline Streaming H√≠brido (Dataset 2)

  * **Mecanismo:** `Structured Streaming` con `foreachBatch`.
  * **L√≥gica Clave (dentro de `process_batch`):**
    1.  **Selecci√≥n del √öltimo Estado:** Se utiliza una **funci√≥n de ventana (`ROW_NUMBER()`)** sobre el *batch* est√°tico (`current_df`) para identificar y seleccionar el evento m√°s reciente (`Timestamp_Evento`) por `ID_Vuelo`, resolviendo el problema de duplicaci√≥n.
    2.  **Uni√≥n H√≠brida:** Se realiza un **Left Join** entre el √∫ltimo estado operativo (Streaming) y la tabla est√°tica de Silver (Dataset 1).

-----

## üìà 5. Visualizaci√≥n y M√©tricas de Negocio

El **Dashboard de Databricks SQL** ofrece una visi√≥n unificada de las m√©tricas cr√≠ticas:

  * **Cantidad de vuelvos (Hist√≥rico):** An√°lisis de cantidad de vuelos realizados.
  * **Pasajeros por mes:** Cantidad de pasajeros por mes.
 
  
-----

## üõ†Ô∏è 6. Despliegue y Ejecuci√≥n

### 6.1. Requisitos

  * Terraform CLI, Azure CLI.
  * Credenciales de un *Service Principal* de Azure.

### 6.2. Despliegue de Infraestructura (Terraform)

Debes configurar el archivo viables con el valor. la variable "prefix" es importante. ya que algunos servicio de azure requiere nombres √∫nicos.

```bash
# Inicializaci√≥n 
terraform init

# Vista previa de los cambios a realizar
terraform plan

# Aplicaci√≥n de los cambios
terraform apply
```


### 6.3. Ejecuci√≥n del Pipeline

1. **Configuraci√≥n de Secretos:** Las credenciales de Event Hubs deben configurarse a trav√©s de Azure Key Vault y referenciarse en Databricks mediante **Secret Scopes**.
2. **Configuraci√≥n de conexi√≥n de Data Factory:** Configurar y validar la conexi√≥n de Data Factory al workspace de Databricks.
3. **Configuraci√≥n del conector de Databricks:** El conector de Databricks debe tener permisos de Contributor Storage Blob en el bucket del metastore.
4. **Arranque:** Azure Data Factory activa los *notebooks* de Batch. El notebook de streaming se debe ejecutar por separado desde Databricks.


### 7. Pendientes

1. **Terraform:** Como se menciona en la ejecuci√≥n del pipeline, hay configuraciones manuales que se deben realizar. Quedaron pendientes de agregar como mejora para seguir investigando. Tambi√©n mencionar que solo se us√≥ el proveedor de Azure, pero tambi√©n existe el de Databricks, que puede ser una mejora para incorporar en alguna versi√≥n futura del proyecto.
